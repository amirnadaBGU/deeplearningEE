{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import libraries #",
   "id": "90012f9408713e6"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-02T08:08:05.313563Z",
     "start_time": "2025-04-02T08:08:02.921477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from jinja2.compiler import F\n",
    "from sympy import false\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import time"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Download MNIST ##",
   "id": "7b08d78e66b4285b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T08:08:08.123479Z",
     "start_time": "2025-04-02T08:08:08.085438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a transform to convert PIL images to tensors.\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Downloading the dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ],
   "id": "bd2acf21fb2e7369",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Some DataSet Examination ##",
   "id": "7825aac1f5e7421e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T08:09:43.889471Z",
     "start_time": "2025-04-02T08:09:43.885448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random_sample = random.randint(1,2000)\n",
    "data,label = train_dataset[random_sample]\n",
    "data_np = data.numpy()\n",
    "min_val, max_val = data_np.min(), data_np.max()\n",
    "median_val = np.median(data_np)\n",
    "\n",
    "print(f\"Label is: {label}; background value is {median_val}; max value  is : {max_val}, min value  is : {min_val}\")"
   ],
   "id": "22a065ad3634e147",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label is: 1; background value is 0.0; max value  is : 1.0, min value  is : 0.0\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T08:09:45.186257Z",
     "start_time": "2025-04-02T08:09:45.181257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img = data.squeeze().detach().cpu().numpy()\n",
    "plt.imsave('output.jpg', img, cmap='gray' if img.ndim == 2 else None)\n"
   ],
   "id": "ac92142528a796ca",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define CNN ##\n",
   "id": "631ca450caa8db72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 5, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(5, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x) # softmax is included in the loss function\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device} is in use\")\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "ebf5b2238c83349c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Loop ##",
   "id": "3ed665a8eeec76a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training loop:\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "# Data Split\n",
    "# Define the split ratio\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "\n",
    "# Compute sizes for each split\n",
    "total_size = len(train_dataset)\n",
    "train_size = int(train_ratio * total_size)\n",
    "val_size = total_size - train_size  # ensures the sum is equal to total_size\n",
    "\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "# Create dataloaders for each subset\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_correct = []\n",
    "val_correct = []\n",
    "\n",
    "total_samples = len(train_dataset)\n",
    "n_iterations = math.ceil(total_samples/batch_size)\n",
    "print(f\"Number of iterations per epoch: {n_iterations}\")\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    trn_corr = 0\n",
    "    val_corr = 0\n",
    "    for b,(images,labels) in enumerate(train_loader):\n",
    "    # Train\n",
    "        # Transfer data to device:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass:\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Track the learning\n",
    "        predicted = torch.max(outputs.data, 1)[1] # sum correct predictions\n",
    "        batch_corr = (predicted ==labels).sum().item() # how many correct from this batch\n",
    "        trn_corr += batch_corr # keep track as we go along\n",
    "\n",
    "        # Back propagation:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print results:\n",
    "        if b%600==0:\n",
    "            print(f'Epoch {epoch+1}/{epochs} Batch: {b} Loss: {loss.item():.4f}')\n",
    "        train_losses.append(loss)\n",
    "        train_correct.append(trn_corr)\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        for b,(val_images,val_labels) in enumerate(val_loader):\n",
    "            val_images = val_images.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            outputs_val = model(val_images)\n",
    "            # Track the learning\n",
    "            predicted = torch.max(outputs_val.data, 1)[1] # sum correct predictions\n",
    "            val_corr = (predicted ==val_labels).sum().item() # how many correct from this batch\n",
    "            val_corr += batch_corr # keep track as we go along\n",
    "        loss=criterion(outputs_val,val_labels)\n",
    "        val_losses.append(loss)\n",
    "        val_correct.append(val_corr)\n",
    "\n",
    "finish_time = time.time()\n",
    "total_time = finish_time - start_time\n",
    "print(f\"Training took time: {total_time/60} minutes\")"
   ],
   "id": "5f53eff92961a07d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
